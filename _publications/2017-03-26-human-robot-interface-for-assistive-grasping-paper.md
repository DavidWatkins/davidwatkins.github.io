---
title: "Human Robot Interface for Assistive Grasping"
collection: publications
permalink: /publication/2017-03-26-human-robot-interface-for-assistive-grasping-paper
excerpt: ''
date: 2017-03-26
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/1804.02462'
citation: 'David Watkins-Valls, Chaiwen Chou, Caroline Weinberg, Jacob Varley, Kenneth Lyons, Sanjay Joshi, Lynne Weber, Joel Stein, and Peter Allen. "Human Robot Interface for Assistive Grasping." arXiv preprint arXiv:1804.02462 (2018).'
---

# Abstract
This work describes a new human-in-the-loop (HitL) assistive grasping system for individuals with varying levels of physical capabilities. We investigated the feasibility of using four potential input devices with our assistive grasping system interface, using able-bodied individuals to define a set of quantitative metrics that could be used to assess an assistive grasping system. We then took these measurements and created a generalized benchmark for evaluating the effectiveness of any arbitrary input device into a HitL grasping system. The four input devices were a mouse, a speech recognition device, an assistive switch, and a novel sEMG device developed by our group that was connected either to the forearm or behind the ear of the subject. These preliminary results provide insight into how different interface devices perform for generalized assistive grasping tasks and also highlight the potential of sEMG based control for severely disabled individuals.


David Watkins-Valls, Chaiwen Chou, Caroline Weinberg, Jacob Varley, Kenneth Lyons, Sanjay Joshi, Lynne Weber, Joel Stein, and Peter Allen. "Human Robot Interface for Assistive Grasping." arXiv preprint arXiv:1804.02462 (2018).
<a href='https://arxiv.org/abs/1804.02462'>Paper</a> | [website](http://crlab.cs.columbia.edu/HumanRobotInterfaceforAssistiveGrasping/)
